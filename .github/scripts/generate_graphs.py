#!/usr/bin/env python3
"""
Generate JSON-LD graphs for vocabulary directories.

Repository: WCRP-constants
Generated by CMIP Workflows Copier Template

This script is an alternative to using the `ld2graph` command.
It can be used in GitHub Actions workflows to generate graphs.

Usage:
    python generate_graphs.py --dirs '["vocab1", "vocab2"]'
    python generate_graphs.py --all
    python generate_graphs.py --dir vocab1
"""

import argparse
import json
import sys
from pathlib import Path
from typing import List, Dict, Any
import subprocess


def find_vocab_directories(base_path: Path = Path(".")) -> List[Path]:
    """
    Find all vocabulary directories (those with _context files).
    
    Args:
        base_path: Base directory to search from
        
    Returns:
        List of vocabulary directory paths
    """
    skip_dirs = {"docs", "summaries", ".github", "project", "ignore", ".git"}
    vocab_dirs = []
    
    for item in base_path.iterdir():
        if not item.is_dir():
            continue
        
        if item.name in skip_dirs or item.name.startswith("."):
            continue
        
        # Check for _context file
        if (item / "_context").exists():
            vocab_dirs.append(item)
            print(f"Found vocabulary directory: {item.name}")
    
    return vocab_dirs


def generate_graph_with_ld2graph(vocab_dir: Path) -> Dict[str, Any]:
    """
    Generate graph using the ld2graph command.
    
    Args:
        vocab_dir: Path to vocabulary directory
        
    Returns:
        Dictionary with status information
    """
    result = {
        "directory": vocab_dir.name,
        "status": "success",
        "message": "",
        "files_created": []
    }
    
    try:
        # Run ld2graph command
        process = subprocess.run(
            ["ld2graph", "."],
            cwd=vocab_dir,
            capture_output=True,
            text=True,
            timeout=60
        )
        
        if process.returncode != 0:
            result["status"] = "failed"
            result["message"] = f"ld2graph failed: {process.stderr}"
            return result
        
        # Check if graph.jsonld was created
        graph_file = vocab_dir / "graph.jsonld"
        if not graph_file.exists():
            result["status"] = "warning"
            result["message"] = "graph.jsonld not created"
            return result
        
        result["files_created"].append("graph.jsonld")
        
        # Create minified version
        with open(graph_file, 'r') as f:
            graph_data = json.load(f)
        
        # Write minified version
        min_file = vocab_dir / "graph.min.json"
        with open(min_file, 'w') as f:
            json.dump(graph_data, f, separators=(',', ':'))
        result["files_created"].append("graph.min.json")
        
        # Create copies without extension (for content negotiation)
        for name in ["graph", "graph.json"]:
            target = vocab_dir / name
            target.write_bytes(min_file.read_bytes())
            result["files_created"].append(name)
        
        result["message"] = "Generated successfully"
        
    except subprocess.TimeoutExpired:
        result["status"] = "failed"
        result["message"] = "Timeout after 60 seconds"
    except Exception as e:
        result["status"] = "failed"
        result["message"] = str(e)
    
    return result


def generate_graph_python(vocab_dir: Path) -> Dict[str, Any]:
    """
    Generate graph using pure Python (alternative implementation).
    
    This is a placeholder for a future Python-only implementation.
    Currently just calls ld2graph.
    
    Args:
        vocab_dir: Path to vocabulary directory
        
    Returns:
        Dictionary with status information
    """
    # TODO: Implement pure Python graph generation
    # For now, fall back to ld2graph
    print(f"  Note: Using ld2graph command (pure Python implementation not yet available)")
    return generate_graph_with_ld2graph(vocab_dir)


def print_summary(results: List[Dict[str, Any]]):
    """Print a summary table of results."""
    print("\n" + "="*60)
    print("GRAPH GENERATION SUMMARY")
    print("="*60)
    
    # Count statuses
    success = sum(1 for r in results if r["status"] == "success")
    failed = sum(1 for r in results if r["status"] == "failed")
    warning = sum(1 for r in results if r["status"] == "warning")
    
    print(f"\nTotal: {len(results)} directories")
    print(f"  ✓ Success: {success}")
    print(f"  ✗ Failed: {failed}")
    print(f"  ⚠ Warnings: {warning}")
    
    # Detailed results
    print("\nDetailed Results:")
    print("-" * 60)
    for result in results:
        status_icon = {
            "success": "✓",
            "failed": "✗",
            "warning": "⚠"
        }.get(result["status"], "?")
        
        print(f"{status_icon} {result['directory']:20s} {result['message']}")
        if result["files_created"]:
            print(f"  Files: {', '.join(result['files_created'])}")
    
    print("="*60 + "\n")


def main():
    parser = argparse.ArgumentParser(
        description="Generate JSON-LD graphs for vocabulary directories"
    )
    parser.add_argument(
        "--dirs",
        type=str,
        help='JSON array of directory names (e.g., \'["vocab1", "vocab2"]\')'
    )
    parser.add_argument(
        "--dir",
        type=str,
        help="Single directory to process"
    )
    parser.add_argument(
        "--all",
        action="store_true",
        help="Process all vocabulary directories"
    )
    parser.add_argument(
        "--method",
        choices=["ld2graph", "python"],
        default="ld2graph",
        help="Method to use for graph generation (default: ld2graph)"
    )
    parser.add_argument(
        "--output-summary",
        action="store_true",
        help="Output GitHub Actions summary markdown"
    )
    
    args = parser.parse_args()
    
    # Determine which directories to process
    if args.dirs:
        # Parse JSON array from command line
        try:
            dir_names = json.loads(args.dirs)
            vocab_dirs = [Path(name) for name in dir_names]
        except json.JSONDecodeError:
            print("Error: --dirs must be a valid JSON array", file=sys.stderr)
            return 1
    elif args.dir:
        vocab_dirs = [Path(args.dir)]
    elif args.all:
        vocab_dirs = find_vocab_directories()
    else:
        print("Error: Must specify --dirs, --dir, or --all", file=sys.stderr)
        return 1
    
    if not vocab_dirs:
        print("No vocabulary directories to process")
        return 0
    
    print(f"\nProcessing {len(vocab_dirs)} directories...\n")
    
    # Generate graphs
    results = []
    for vocab_dir in vocab_dirs:
        if not vocab_dir.exists():
            results.append({
                "directory": vocab_dir.name,
                "status": "failed",
                "message": "Directory not found",
                "files_created": []
            })
            continue
        
        print(f"Processing: {vocab_dir.name}")
        
        if args.method == "ld2graph":
            result = generate_graph_with_ld2graph(vocab_dir)
        else:
            result = generate_graph_python(vocab_dir)
        
        results.append(result)
        print(f"  Status: {result['status']} - {result['message']}")
    
    # Print summary
    print_summary(results)
    
    # Output GitHub Actions summary if requested
    if args.output_summary:
        summary_file = Path(os.environ.get("GITHUB_STEP_SUMMARY", "/tmp/summary.md"))
        with open(summary_file, "a") as f:
            f.write("## Graph Generation Report\n\n")
            f.write("| Directory | Status | Details |\n")
            f.write("|-----------|--------|----------|\n")
            
            for result in results:
                status_emoji = {
                    "success": "✅",
                    "failed": "❌",
                    "warning": "⚠️"
                }.get(result["status"], "❓")
                
                f.write(f"| `{result['directory']}` | {status_emoji} | {result['message']} |\n")
            
            f.write(f"\n**Completed**: {len(results)} directories processed\n")
    
    # Return exit code
    if any(r["status"] == "failed" for r in results):
        return 1
    return 0


if __name__ == "__main__":
    import os
    sys.exit(main())
